# server/main.py â€” Hotfix 4 en 1 (idioma + botones + audio + fotos + tickets)
# ---------------------------------------------------------------------------
# QuÃ© corrige:
# 1) Auto-detecciÃ³n de idioma por MENSAJE (no global) y menÃº en el idioma del usuario.
# 2) TranscripciÃ³n de audios (WhatsApp OGG/MP3) con Whisper y respuesta en el mismo idioma.
# 3) AnÃ¡lisis bÃ¡sico de fotos con GPT-4o (visiÃ³n) y respuesta en el mismo idioma.
# 4) EnvÃ­o de ticket a Google Sheets vÃ­a Apps Script (si SHEET_WEBHOOK_URL estÃ¡ configurada).
#
# Requisitos de entorno (Render â†’ Environment):
#   OPENAI_API_KEY           (obligatorio)
#   WA_TOKEN                 (obligatorio â€“ token de la app de Meta)
#   WA_PHONE_ID              (obligatorio â€“ phone number id de WhatsApp)
#   SHEET_WEBHOOK_URL        (opcional â€“ URL del Apps Script para registrar tickets)
#   OPENAI_MODEL=gpt-4o-mini (por defecto)
#   OPENAI_TEMP=0.2          (por defecto)
#
# Endpoints Ãºtiles:
#   GET  /_debug/health   -> estado y variables clave
#   GET  /handoff         -> tickets locales (respaldo en /tmp/handoff.json)
#   POST /webhook         -> webhook de Meta
# ---------------------------------------------------------------------------

from __future__ import annotations
import os, io, time, json, base64, re, typing, mimetypes, requests, pathlib
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse, PlainTextResponse, HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI

app = FastAPI(title="Dental-LLM")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)

# --- Config ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
WA_TOKEN        = os.getenv("WA_TOKEN", "")
WA_PHONE_ID     = os.getenv("WA_PHONE_ID", "")
SHEET_WEBHOOK   = os.getenv("SHEET_WEBHOOK_URL", "")
OPENAI_MODEL    = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
OPENAI_TEMP     = float(os.getenv("OPENAI_TEMP", "0.2"))

client = OpenAI(api_key=OPENAI_API_KEY)

SYSTEM_PROMPT = (
    "You are NochGPT, a helpful dental laboratory assistant. "
    "Focus strictly on dental topics (prosthetics, implants, zirconia, CAD/CAM, workflows, materials). "
    "Be concise and practical. Always reply in the same language as the user."
)

# ===== Utilidades de idioma =====
def detect_lang(t: str) -> str:
    s = (t or "").strip().lower()
    # Atajos por palabras comunes
    if re.search(r"[Ã¡Ã©Ã­Ã³ÃºÃ±Â¿Â¡]|(hola|gracias|buenas|cotizar|implante|zirconia)", s): return "es"
    if re.search(r"[Ã§Ã£Ãµ]|(olÃ¡|obrigado)", s): return "pt"
    if re.search(r"[Ã Ã¢Ã§Ã©Ã¨ÃªÃ«Ã®Ã¯Ã´Ã¹Ã»Ã¼Ã¿Å“]|(bonjour|merci)", s): return "fr"
    if re.search(r"[\u0400-\u04FF]|(ÑÐ¿Ð°ÑÐ¸Ð±Ð¾|Ð¿Ñ€Ð¸Ð²ÐµÑ‚)", s): return "ru"  # cirÃ­lico
    if re.search(r"[\u0900-\u097F]", s): return "hi"                   # devanagari (hindi)
    if re.search(r"[\u0600-\u06FF]", s): return "ar"                   # Ã¡rabe
    if re.search(r"[\u4e00-\u9fff]", s): return "zh"                   # chino
    if re.search(r"[\u3040-\u30ff]", s): return "ja"                   # japonÃ©s
    return "en"

# Textos por idioma
TEXTS = {
    "es": {
        "hi": "Â¡Hola! Â¿En quÃ© puedo ayudarte hoy en el Ã¡mbito dental?\n\nElige una opciÃ³n:",
        "menu": ["Planes y precios", "Tiempos de entrega", "Hablar con humano"],
        "audio_wait": "ðŸŽ™ï¸ RecibÃ­ tu audio, lo estoy transcribiendoâ€¦",
        "audio_fail": "No pude transcribir el audio. Â¿PodrÃ­as escribir un breve resumen?",
        "img_wait": "ðŸ–¼ï¸ RecibÃ­ tu imagen, la estoy analizandoâ€¦",
        "img_fail": "Lo siento, no pude analizar la imagen. Â¿Puedes describirme quÃ© deseas revisar?",
        "handoff_ask": ("ðŸ‘¤ Te conecto con un asesor. Comparte por favor:\n"
                        "â€¢ Nombre\nâ€¢ Tema (implante, zirconia, urgencia)\n"
                        "â€¢ Horario preferido y telÃ©fono si es otro"),
        "handoff_ok": "âœ… Gracias. Tu solicitud fue registrada; un asesor te contactarÃ¡ pronto.",
    },
    "en": {
        "hi": "Hi! How can I help you today with dental topics?\n\nChoose an option:",
        "menu": ["Plans & pricing", "Turnaround times", "Talk to a human"],
        "audio_wait": "ðŸŽ™ï¸ I received your audio, transcribingâ€¦",
        "audio_fail": "I couldnâ€™t transcribe the audio. Could you type a short summary?",
        "img_wait": "ðŸ–¼ï¸ I received your image, analyzingâ€¦",
        "img_fail": "Sorry, I couldn't analyze the image. Can you describe what you need?",
        "handoff_ask": ("ðŸ‘¤ Iâ€™ll connect you with an agent. Please share:\n"
                        "â€¢ Name\nâ€¢ Topic (implant, zirconia, urgent)\n"
                        "â€¢ Preferred time and phone if different"),
        "handoff_ok": "âœ… Thanks. Your request was recorded; an agent will contact you soon.",
    },
    "pt": {
        "hi": "OlÃ¡! Como posso ajudar hoje com temas dentÃ¡rios?\n\nEscolha uma opÃ§Ã£o:",
        "menu": ["Planos e preÃ§os", "Prazos", "Falar com humano"],
        "audio_wait": "ðŸŽ™ï¸ Recebi seu Ã¡udio, transcrevendoâ€¦",
        "audio_fail": "NÃ£o consegui transcrever o Ã¡udio. Pode escrever um resumo?",
        "img_wait": "ðŸ–¼ï¸ Recebi sua imagem, analisandoâ€¦",
        "img_fail": "Desculpe, nÃ£o consegui analisar a imagem. Pode descrever?",
        "handoff_ask": ("ðŸ‘¤ Vou conectÃ¡-lo a um atendente. Envie:\n"
                        "â€¢ Nome\nâ€¢ Tema (implante, zircÃ´nia, urgÃªncia)\n"
                        "â€¢ HorÃ¡rio preferido e telefone se outro"),
        "handoff_ok": "âœ… Obrigado. Sua solicitaÃ§Ã£o foi registrada; entraremos em contato.",
    },
    "fr": {
        "hi": "Bonjour ! Comment puis-je vous aider aujourdâ€™hui en dentaire ?\n\nChoisissez une option :",
        "menu": ["Offres & tarifs", "DÃ©lais", "Parler Ã  un humain"],
        "audio_wait": "ðŸŽ™ï¸ Jâ€™ai reÃ§u votre audio, transcriptionâ€¦",
        "audio_fail": "Je nâ€™ai pas pu transcrire lâ€™audio. Pouvez-vous Ã©crire un rÃ©sumÃ© ?",
        "img_wait": "ðŸ–¼ï¸ Image reÃ§ue, analyseâ€¦",
        "img_fail": "DÃ©solÃ©, je nâ€™ai pas pu analyser lâ€™image. DÃ©crivez-moi ce que vous voulez.",
        "handoff_ask": ("ðŸ‘¤ Je vous mets en relation avec un conseiller. Donnez :\n"
                        "â€¢ Nom\nâ€¢ Sujet (implant, zircone, urgent)\n"
                        "â€¢ Horaire prÃ©fÃ©rÃ© et tÃ©lÃ©phone si diffÃ©rent"),
        "handoff_ok": "âœ… Merci. Votre demande a Ã©tÃ© enregistrÃ©e ; un conseiller vous contactera.",
    },
    "ru": {
        "hi": "ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð§ÐµÐ¼ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ð¿Ð¾ ÑÑ‚Ð¾Ð¼Ð°Ñ‚Ð¾Ð»Ð¾Ð³Ð¸Ð¸?\n\nÐ’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¾Ð¿Ñ†Ð¸ÑŽ:",
        "menu": ["ÐŸÐ»Ð°Ð½Ñ‹ Ð¸ Ñ†ÐµÐ½Ñ‹", "Ð¡Ñ€Ð¾ÐºÐ¸", "Ð¡Ð²ÑÐ·Ð°Ñ‚ÑŒÑÑ Ñ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ¾Ð¼"],
        "audio_wait": "ðŸŽ™ï¸ ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ð» Ð°ÑƒÐ´Ð¸Ð¾, Ñ€Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²Ñ‹Ð²Ð°ÑŽâ€¦",
        "audio_fail": "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ñ€Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð°ÑƒÐ´Ð¸Ð¾. ÐÐ°Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼?",
        "img_wait": "ðŸ–¼ï¸ Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾, Ð°Ð½Ð°Ð»Ð¸Ð·â€¦",
        "img_fail": "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ. ÐžÐ¿Ð¸ÑˆÐ¸Ñ‚Ðµ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼?",
        "handoff_ask": "ðŸ‘¤ Ð¡Ð¾ÐµÐ´Ð¸Ð½ÑŽ Ñ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð¼. Ð£ÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ð¸Ð¼Ñ, Ñ‚ÐµÐ¼Ñƒ Ð¸ ÑƒÐ´Ð¾Ð±Ð½Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ.",
        "handoff_ok": "âœ… Ð—Ð°ÑÐ²ÐºÐ° Ð¿Ñ€Ð¸Ð½ÑÑ‚Ð°. ÐœÑ‹ ÑÐ²ÑÐ¶ÐµÐ¼ÑÑ Ñ Ð²Ð°Ð¼Ð¸.",
    },
    "hi": {
        "hi": "à¤¨à¤®à¤¸à¥à¤¤à¥‡! à¤¦à¤‚à¤¤ à¤µà¤¿à¤·à¤¯à¥‹à¤‚ à¤®à¥‡à¤‚ à¤†à¤œ à¤®à¥ˆà¤‚ à¤•à¥ˆà¤¸à¥‡ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤?\n\nà¤à¤• à¤µà¤¿à¤•à¤²à¥à¤ª à¤šà¥à¤¨à¥‡à¤‚:",
        "menu": ["à¤ªà¥à¤²à¤¾à¤¨ à¤”à¤° à¤•à¥€à¤®à¤¤", "à¤Ÿà¤°à¥à¤¨à¤…à¤°à¤¾à¤‰à¤‚à¤¡ à¤Ÿà¤¾à¤‡à¤®", "à¤®à¤¾à¤¨à¤µ à¤¸à¥‡ à¤¬à¤¾à¤¤ à¤•à¤°à¥‡à¤‚"],
        "audio_wait": "ðŸŽ™ï¸ à¤†à¤ªà¤•à¤¾ à¤‘à¤¡à¤¿à¤¯à¥‹ à¤®à¤¿à¤²à¤¾, à¤²à¤¿à¤ªà¥à¤¯à¤‚à¤¤à¤°à¤£ à¤•à¤° à¤°à¤¹à¤¾ à¤¹à¥‚à¤â€¦",
        "audio_fail": "à¤‘à¤¡à¤¿à¤¯à¥‹ à¤²à¤¿à¤ªà¥à¤¯à¤‚à¤¤à¤°à¤£ à¤¨à¤¹à¥€à¤‚ à¤¹à¥‹ à¤¸à¤•à¤¾. à¤•à¥ƒà¤ªà¤¯à¤¾ à¤à¤• à¤›à¥‹à¤Ÿà¤¾ à¤¸à¤¾à¤° à¤²à¤¿à¤–à¥‡à¤‚à¥¤",
        "img_wait": "ðŸ–¼ï¸ à¤†à¤ªà¤•à¥€ à¤›à¤µà¤¿ à¤®à¤¿à¤²à¥€, à¤µà¤¿à¤¶à¥à¤²à¥‡à¤·à¤£ à¤•à¤° à¤°à¤¹à¤¾ à¤¹à¥‚à¤â€¦",
        "img_fail": "à¤›à¤µà¤¿ à¤•à¤¾ à¤µà¤¿à¤¶à¥à¤²à¥‡à¤·à¤£ à¤¨à¤¹à¥€à¤‚ à¤¹à¥‹ à¤¸à¤•à¤¾. à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¬à¤¤à¤¾à¤à¤‚ à¤•à¥à¤¯à¤¾ à¤šà¤¾à¤¹à¤¿à¤à¥¤",
        "handoff_ask": "ðŸ‘¤ à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥‹ à¤à¤œà¥‡à¤‚à¤Ÿ à¤¸à¥‡ à¤œà¥‹à¤¡à¤¼à¥‚à¤à¤—à¤¾. à¤¨à¤¾à¤®, à¤µà¤¿à¤·à¤¯, à¤ªà¤¸à¤‚à¤¦à¥€à¤¦à¤¾ à¤¸à¤®à¤¯ à¤­à¥‡à¤œà¥‡à¤‚à¥¤",
        "handoff_ok": "âœ… à¤…à¤¨à¥à¤°à¥‹à¤§ à¤¦à¤°à¥à¤œ à¤¹à¥‹ à¤—à¤¯à¤¾. à¤¹à¤® à¤†à¤ªà¤¸à¥‡ à¤¸à¤‚à¤ªà¤°à¥à¤• à¤•à¤°à¥‡à¤‚à¤—à¥‡à¥¤",
    },
    "ar": {
        "hi": "Ù…Ø±Ø­Ø¨Ù‹Ø§! ÙƒÙŠÙ Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„ÙŠÙˆÙ… ÙÙŠ Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø·Ø¨ Ø§Ù„Ø£Ø³Ù†Ø§Ù†ØŸ\n\nØ§Ø®ØªØ± Ø®ÙŠØ§Ø±Ù‹Ø§:",
        "menu": ["Ø§Ù„Ø®Ø·Ø· ÙˆØ§Ù„Ø£Ø³Ø¹Ø§Ø±", "Ø£ÙˆÙ‚Ø§Øª Ø§Ù„ØªØ³Ù„ÙŠÙ…", "Ø§Ù„ØªØ­Ø¯Ø« Ø¥Ù„Ù‰ Ù…ÙˆØ¸Ù"],
        "audio_wait": "ðŸŽ™ï¸ Ø§Ø³ØªÙ„Ù…Øª Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø§Ù„ØµÙˆØªÙŠ ÙˆØ£Ù‚ÙˆÙ… Ø¨ÙƒØªØ§Ø¨ØªÙ‡â€¦",
        "audio_fail": "ØªØ¹Ø°Ø± ØªÙØ±ÙŠØº Ø§Ù„ØµÙˆØª. Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ÙƒØªØ§Ø¨Ø© Ù…Ù„Ø®Øµ Ù‚ØµÙŠØ±ØŸ",
        "img_wait": "ðŸ–¼ï¸ Ø§Ø³ØªÙ„Ù…Øª Ø§Ù„ØµÙˆØ±Ø© ÙˆØ£Ù‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„Ù‡Ø§â€¦",
        "img_fail": "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©. ØµÙ Ù…Ø§ ØªØ±ÙŠØ¯ ÙØ­ØµÙ‡.",
        "handoff_ask": "ðŸ‘¤ Ø³Ø£ÙˆØµÙ„Ùƒ Ø¨Ù…Ø³ØªØ´Ø§Ø±. Ø£Ø±Ø³Ù„ Ø§Ù„Ø§Ø³Ù… ÙˆØ§Ù„Ù…ÙˆØ¶ÙˆØ¹ ÙˆØ§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ÙØ¶Ù„.",
        "handoff_ok": "âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø·Ù„Ø¨ÙƒØŒ Ø³ÙŠØªÙˆØ§ØµÙ„ Ù…Ø¹Ùƒ Ù…Ø³ØªØ´Ø§Ø± Ù‚Ø±ÙŠØ¨Ù‹Ø§.",
    },
    "zh": {
        "hi": "ä½ å¥½ï¼ä»Šå¤©åœ¨ç‰™ç§‘æ–¹é¢æˆ‘èƒ½å¸®ä½ ä»€ä¹ˆï¼Ÿ\n\nè¯·é€‰æ‹©ï¼š",
        "menu": ["æ–¹æ¡ˆä¸Žä»·æ ¼", "äº¤ä»˜æ—¶é—´", "è”ç³»äººå·¥"],
        "audio_wait": "ðŸŽ™ï¸ æ”¶åˆ°ä½ çš„è¯­éŸ³ï¼Œæ­£åœ¨è½¬å†™â€¦",
        "audio_fail": "æ— æ³•è½¬å†™è¯­éŸ³ã€‚è¯·ç®€è¦ç”¨æ–‡å­—è¯´æ˜Žã€‚",
        "img_wait": "ðŸ–¼ï¸ æ”¶åˆ°ä½ çš„å›¾ç‰‡ï¼Œæ­£åœ¨åˆ†æžâ€¦",
        "img_fail": "æŠ±æ­‰ï¼Œæ— æ³•åˆ†æžå›¾ç‰‡ã€‚è¯·ç”¨æ–‡å­—æè¿°ä½ çš„éœ€æ±‚ã€‚",
        "handoff_ask": "ðŸ‘¤ æˆ‘å°†ä¸ºä½ è”ç³»äººå·¥ã€‚è¯·æä¾›å§“åã€ä¸»é¢˜å’Œæ–¹ä¾¿æ—¶é—´ã€‚",
        "handoff_ok": "âœ… å·²ç™»è®°ä½ çš„è¯·æ±‚ï¼Œç¨åŽä¼šæœ‰å·¥ä½œäººå‘˜è”ç³»ä½ ã€‚",
    },
    "ja": {
        "hi": "ã“ã‚“ã«ã¡ã¯ï¼æ­¯ç§‘åˆ†é‡Žã§ä»Šæ—¥ã¯ä½•ã‚’ãŠæ‰‹ä¼ã„ã§ãã¾ã™ã‹ï¼Ÿ\n\nã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
        "menu": ["ãƒ—ãƒ©ãƒ³ã¨æ–™é‡‘", "ç´æœŸ", "æ‹…å½“è€…ã¨è©±ã™"],
        "audio_wait": "ðŸŽ™ï¸ éŸ³å£°ã‚’å—ä¿¡ã€æ–‡å­—èµ·ã“ã—ä¸­â€¦",
        "audio_fail": "æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è¦ç‚¹ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§é€ã£ã¦ãã ã•ã„ã€‚",
        "img_wait": "ðŸ–¼ï¸ ç”»åƒã‚’å—ä¿¡ã€è§£æžä¸­â€¦",
        "img_fail": "ç”»åƒã‚’è§£æžã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å†…å®¹ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§æ•™ãˆã¦ãã ã•ã„ã€‚",
        "handoff_ask": "ðŸ‘¤ æ‹…å½“è€…ã«ãŠã¤ãªãŽã—ã¾ã™ã€‚ãŠåå‰ãƒ»å†…å®¹ãƒ»å¸Œæœ›æ™‚é–“ã‚’é€ã£ã¦ãã ã•ã„ã€‚",
        "handoff_ok": "âœ… å—ä»˜ã—ã¾ã—ãŸã€‚æ‹…å½“è€…ã‚ˆã‚Šã”é€£çµ¡ã—ã¾ã™ã€‚",
    },
}

def T(lang: str, key: str) -> str:
    d = TEXTS.get(lang) or TEXTS["en"]
    return d.get(key, TEXTS["en"][key])

# ===== WhatsApp helpers =====
def wa_send_json(payload: dict):
    url = f"https://graph.facebook.com/v21.0/{WA_PHONE_ID}/messages"
    h = {"Authorization": f"Bearer {WA_TOKEN}", "Content-Type":"application/json"}
    r = requests.post(url, headers=h, json=payload, timeout=30)
    try:
        return r.status_code, r.json()
    except Exception:
        return r.status_code, {"raw": r.text}

def wa_send_text(to: str, text: str):
    return wa_send_json({"messaging_product":"whatsapp","to":to,"type":"text","text":{"body":text}})

def wa_send_menu(to: str, lang: str):
    # Botones localizados
    a,b,c = TEXTS.get(lang, TEXTS["en"])["menu"]
    body = T(lang,"hi")
    payload = {
        "messaging_product":"whatsapp","to":to,"type":"interactive",
        "interactive":{
            "type":"button",
            "body":{"text": body},
            "action":{"buttons":[
                {"type":"reply","reply":{"id":"plans","title":a}},
                {"type":"reply","reply":{"id":"tat","title":b}},
                {"type":"reply","reply":{"id":"human","title":c}},
            ]}
        }
    }
    return wa_send_json(payload)

def wa_media_url(media_id: str) -> str:
    url = f"https://graph.facebook.com/v21.0/{media_id}"
    h = {"Authorization": f"Bearer {WA_TOKEN}"}
    r = requests.get(url, headers=h, timeout=30)
    r.raise_for_status()
    return r.json()["url"]

def wa_media_bytes(signed_url: str) -> bytes:
    h = {"Authorization": f"Bearer {WA_TOKEN}"}
    r = requests.get(signed_url, headers=h, timeout=60)
    r.raise_for_status()
    return r.content

# ===== Tickets (Google Sheets) =====
HANDOFF_FILE = "/tmp/handoff.json"
def save_local_ticket(item: dict):
    data = []
    if pathlib.Path(HANDOFF_FILE).exists():
        try:
            data = json.loads(pathlib.Path(HANDOFF_FILE).read_text("utf-8"))
        except Exception:
            data = []
    data.append(item)
    pathlib.Path(HANDOFF_FILE).write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

def send_ticket_sheet(item: dict):
    if not SHEET_WEBHOOK:
        return False, "no SHEET_WEBHOOK_URL"
    try:
        r = requests.post(SHEET_WEBHOOK, json=item, timeout=30)
        ok = (200 <= r.status_code < 300)
        return ok, r.text
    except Exception as e:
        return False, str(e)

# ===== Flow helpers =====
def analyze_text(user_text: str, lang: str) -> str:
    # Respuesta breve, dental-only, en el idioma detectado
    msg = [
        {"role":"system","content":SYSTEM_PROMPT},
        {"role":"user","content":user_text}
    ]
    resp = client.chat.completions.create(
        model=OPENAI_MODEL, temperature=OPENAI_TEMP, messages=msg
    )
    return resp.choices[0].message.content.strip()

def analyze_image(img_bytes: bytes, lang: str) -> str:
    b64 = base64.b64encode(img_bytes).decode()
    msg = [
        {"role":"system","content":SYSTEM_PROMPT},
        {"role":"user","content":[
            {"type":"text","text":"Describe brevemente la situaciÃ³n clÃ­nica en la imagen y sugiere pasos/precauciones. Responde en "+lang},
            {"type":"input_image","image_data": b64}
        ]}
    ]
    resp = client.chat.completions.create(model="gpt-4o-mini", temperature=OPENAI_TEMP, messages=msg)
    return resp.choices[0].message.content.strip()

def transcribe_audio(audio_bytes: bytes) -> str:
    # Whisper espera un archivo. Enviamos bytes como archivo temporal en memoria.
    # Render usa python3.11, openai==1.x lo soporta.
    fileobj = io.BytesIO(audio_bytes); fileobj.name = "audio.ogg"
    tr = client.audio.transcriptions.create(model="whisper-1", file=fileobj)
    return tr.text.strip()

# ===== Estados simples por usuario =====
STATE = {}  # from -> "waiting_human"

def handle_text(from_number: str, body: str):
    lang = detect_lang(body)
    txt = body.strip().lower()

    # palabra de arranque -> mostrar menÃº
    if txt in {"hola","menu","hi","hello","inicio","start"}:
        wa_send_menu(from_number, lang)
        return True

    # pedir humano
    if txt in {"humano","hablar con humano","asesor","agente","human"}:
        STATE[from_number] = "waiting_human"
        wa_send_text(from_number, T(lang,"handoff_ask"))
        return True

    # completar ticket si estaba esperando
    if STATE.get(from_number) == "waiting_human":
        item = {
            "ts": int(time.time()), "label":"NochGPT",
            "from": from_number, "nombre":"", "tema":"", "contacto": from_number,
            "horario":"", "mensaje": body
        }
        save_local_ticket(item)
        send_ticket_sheet(item)
        wa_send_text(from_number, T(lang,"handoff_ok"))
        STATE[from_number] = "done"
        return True

    # Respuesta LLM normal
    answer = analyze_text(body, lang)
    wa_send_text(from_number, answer)
    return True

# ===== FastAPI =====
@app.get("/_debug/health")
def health():
    return {"ok": True, "cfg":{
        "openai": bool(OPENAI_API_KEY), "wa_token": bool(WA_TOKEN),
        "wa_phone_id": bool(WA_PHONE_ID), "model": OPENAI_MODEL,
        "sheet_webhook": bool(SHEET_WEBHOOK)
    }}

@app.get("/handoff")
def handoff_list():
    if not pathlib.Path(HANDOFF_FILE).exists():
        return []
    return json.loads(pathlib.Path(HANDOFF_FILE).read_text("utf-8"))

@app.post("/webhook")
async def webhook(req: Request):
    data = await req.json()
    try:
        entry = data.get("entry", [])[0]
        change = entry.get("changes", [])[0]
        value  = change.get("value", {})
        msgs   = value.get("messages", [])
        if not msgs:
            return JSONResponse({"status":"ok"})  # status updates, etc.

        msg = msgs[0]
        from_number = msg.get("from")
        msg_type = msg.get("type")

        # --- TEXTO ---
        if msg_type == "text":
            body = msg["text"]["body"]
            handle_text(from_number, body)
            return JSONResponse({"status":"ok"})

        # --- BOTONES (interactive) ---
        if msg_type == "interactive":
            lang = "es"  # pequeÃ±o truco: si vienen de botÃ³n, mantenemos ES por defecto
            btn = msg.get("interactive", {}).get("button_reply") or {}
            btn_id = btn.get("id","")
            if btn_id == "plans":
                # Tu mensaje/plantilla de planes:
                wa_send_text(from_number, "ðŸ’³ Planes: BÃ¡sico $50, Pro $150, Enterprise $500.\nEscrÃ­beme quÃ© necesitas y te cotizo.")
            elif btn_id == "tat":
                wa_send_text(from_number, "â±ï¸ Tiempos tÃ­picos: Zirconia 2â€“4 dÃ­as, Implantes 5â€“7 dÃ­as. Consulta disponibilidad.")
            elif btn_id == "human":
                STATE[from_number] = "waiting_human"
                wa_send_text(from_number, T(lang,"handoff_ask"))
            return JSONResponse({"status":"ok"})

        # --- AUDIO ---
        if msg_type == "audio":
            wa_send_text(from_number, T(detect_lang("hola"), "audio_wait"))
            media_id = msg["audio"]["id"]
            url = wa_media_url(media_id)
            blob = wa_media_bytes(url)
            try:
                text = transcribe_audio(blob)
                handle_text(from_number, text)  # reutiliza lÃ³gica (idioma del texto)
            except Exception:
                wa_send_text(from_number, T(detect_lang("en"), "audio_fail"))
            return JSONResponse({"status":"ok"})

        # --- IMAGEN ---
        if msg_type == "image":
            lang = detect_lang("hola")  # por defecto espaÃ±ol si no tenemos pista
            wa_send_text(from_number, T(lang, "img_wait"))
            media_id = msg["image"]["id"]
            url = wa_media_url(media_id)
            blob = wa_media_bytes(url)
            try:
                out = analyze_image(blob, lang)
                wa_send_text(from_number, out)
            except Exception:
                wa_send_text(from_number, T(lang, "img_fail"))
            return JSONResponse({"status":"ok"})

        # --- DOCUMENTO (PDF u otros) -> por ahora: texto de recibo (resumen despuÃ©s)
        if msg_type == "document":
            wa_send_text(from_number, "ðŸ“„ RecibÃ­ tu archivo. Puedo darte un resumen de texto si me dices quÃ© parte te interesa.")
            return JSONResponse({"status":"ok"})

        # otros tipos
        wa_send_text(from_number, "I received your message. For now I understand text best ðŸ˜‰")
        return JSONResponse({"status":"ok"})

    except Exception as e:
        return JSONResponse({"status":"error","detail":str(e)})

@app.get("/")
def home():
    return HTMLResponse("<b>Dental-LLM corriendo âœ…</b>")
